{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4eL84bCKfxirXrWo8JwdK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imdiegolopes/puc-mvp-04-classificacao-de-risco-de-credito/blob/main/ML_Credit_Risk_Classifier_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Projeto de Classificação de Risco de Crédito\n",
        "\n",
        "## Introdução\n",
        "\n",
        "Este documento apresenta uma análise e implementação de um modelo de machine learning para classificação de risco de crédito. O modelo foi construído a partir do dataset Statlog German Credit Data, que contém informações sobre indivíduos e sua capacidade de honrar dívidas. Para maiores informações acerca do dataset, acesse http://archive.ics.uci.edu/dataset/144/statlog+german+credit+data\n",
        "\n",
        "## Contexto\n",
        "A avaliação do risco de crédito é fundamental para instituições financeiras tomarem decisões sobre empréstimos e outros serviços financeiros. Essa avaliação tradicionalmente baseia-se em métodos estatísticos e análise de crédito manual. No entanto, o uso de machine learning vem ganhando popularidade nos últimos anos, pois pode oferecer análises mais precisas e eficientes.\n",
        "\n",
        "## Objetivos\n",
        "Este projeto tem como objetivos:\n",
        "\n",
        "- Explorar o dataset Statlog German Credit Data.\n",
        "- Implementar um modelo de machine learning para classificação de risco de crédito.\n",
        "- Avaliar o desempenho do modelo.\n",
        "\n",
        "## Metodologia\n",
        "- Exploração de dados: Análise descritiva das variáveis do dataset, identificação de valores faltantes, correlações entre variáveis e visualização de dados.\n",
        "- Pré-processamento de dados: Codificação de variáveis categóricas, tratamento de valores faltantes e normalização de dados numéricos.\n",
        "Seleção de modelo: Escolha de um algoritmo de machine learning adequado para a tarefa de classificação.\n",
        "- Treinamento e validação do modelo: Divisão do dataset em conjuntos de treinamento e teste, treinamento do modelo com o conjunto de treinamento e avaliação do desempenho com o conjunto de teste.\n",
        "- Avaliação do modelo: Análise de métricas de desempenho como acurácia, precisão, r\n",
        "ecall e F1-score.\n",
        "\n",
        "## Resultados\n",
        "Os resultados do projeto serão apresentados em seções separadas, incluindo:\n",
        "\n",
        "- Exploração de dados: Descrição das variáveis e estatísticas resumidas, análise de valores faltantes, visualização de dados e correlações entre variáveis.\n",
        "- Pré-processamento de dados: Descrição das técnicas utilizadas para pré-processar os dados.\n",
        "- Seleção de modelo: Justificativa para a escolha do algoritmo de machine learning.\n",
        "- Treinamento e validação do modelo: Descrição do processo de treinamento e validação, incluindo métricas de desempenho.\n",
        "Avaliação do desempenho: Interpretação das métricas de desempenho e discussão da adequação do modelo.\n",
        "\n",
        "## Identificação do Dataset\n",
        "\n",
        "O código a seguir é responsável por baixar o dataset Statlog German Credit Data usando a biblioteca 'fetch_ucirepo' e identificar os metadados e as variáveis presentes neste dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "daVbE8hi3-el"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8WcjoOiNtg5"
      },
      "outputs": [],
      "source": [
        "# Instalação do scikit-learn (caso não esteja instalado)\n",
        "!pip install scikit-learn\n",
        "!pip install ucimlrepo\n",
        "\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "statlog_german_credit_data = fetch_ucirepo(id=144)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = statlog_german_credit_data.data.features\n",
        "y = statlog_german_credit_data.data.targets\n",
        "\n",
        "# metadata\n",
        "print(statlog_german_credit_data.metadata)\n",
        "\n",
        "# variable information\n",
        "print(statlog_german_credit_data.variables)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explicação das Variáveis do Modelo\n",
        "\n",
        "**Attribute 1:** (qualitative)      \n",
        "  *Status of existing checking account*\n",
        "  - A11: ... < 0 DM\n",
        "  - A12: 0 <= ... < 200 DM\n",
        "  - A13: ... >= 200 DM / salary assignments for at least 1 year\n",
        "  - A14: no checking account\n",
        "\n",
        "**Attribute 2:** (numerical)\n",
        "  - Duration in month\n",
        "\n",
        "**Attribute 3:** (qualitative)\n",
        "  *Credit history*\n",
        "  - A30: no credits taken/ all credits paid back duly\n",
        "  - A31: all credits at this bank paid back duly\n",
        "  - A32: existing credits paid back duly till now\n",
        "  - A33: delay in paying off in the past\n",
        "  - A34: critical account/ other credits existing (not at this bank)\n",
        "\n",
        "**Attribute 4:** (qualitative)\n",
        "  *Purpose*\n",
        "  - A40: car (new)\n",
        "  - A41: car (used)\n",
        "  - A42: furniture/equipment\n",
        "  - A43: radio/television\n",
        "  - A44: domestic appliances\n",
        "  - A45: repairs\n",
        "  - A46: education\n",
        "  - A47: (vacation - does not exist?)\n",
        "  - A48: retraining\n",
        "  - A49: business\n",
        "  - A410: others\n",
        "\n",
        "**Attribute 5:** (numerical)\n",
        "  - Credit amount\n",
        "\n",
        "**Attribute 6:** (qualitative)\n",
        "  *Savings account/bonds*\n",
        "  - A61: ... < 100 DM\n",
        "  - A62: 100 <= ... < 500 DM\n",
        "  - A63: 500 <= ... < 1000 DM\n",
        "  - A64: .. >= 1000 DM\n",
        "  - A65: unknown/ no savings account\n",
        "\n",
        "**Attribute 7:** (qualitative)\n",
        "  *Present employment since*\n",
        "  - A71: unemployed\n",
        "  - A72: ... < 1 year\n",
        "  - A73: 1  <= ... < 4 years  \n",
        "  - A74: 4  <= ... < 7 years\n",
        "  - A75: .. >= 7 years\n",
        "\n",
        "**Attribute 8:** (numerical)\n",
        "  - Installment rate in percentage of disposable income\n",
        "\n",
        "**Attribute 9:** (qualitative)\n",
        "  *Personal status and sex*\n",
        "  - A91: male: divorced/separated\n",
        "  - A92: female: divorced/separated/married\n",
        "  - A93: male: single\n",
        "  - A94: male: married/widowed\n",
        "  - A95: female: single\n",
        "\n",
        "**Attribute 10:** (qualitative)\n",
        "  *Other debtors / guarantors*\n",
        "  - A101: none\n",
        "  - A102: co-applicant\n",
        "  - A103: guarantor\n",
        "\n",
        "**Attribute 11:** (numerical)\n",
        "  - Present residence since\n",
        "\n",
        "**Attribute 12:** (qualitative)\n",
        "  *Property*\n",
        "  - A121: real estate\n",
        "  - A122: if not A121: building society savings agreement/ life insurance\n",
        "  - A123: if not A121/A122: car or other, not in attribute 6\n",
        "  - A124: unknown / no property\n",
        "\n",
        "**Attribute 13:** (numerical)\n",
        "  - Age in years\n",
        "\n",
        "**Attribute 14:** (qualitative)\n",
        "  *Other installment plans*\n",
        "  - A141: bank\n",
        "  - A142: stores\n",
        "  - A143: none\n",
        "\n",
        "**Attribute 15:** (qualitative)\n",
        "  *Housing*\n",
        "  - A151: rent\n",
        "  - A152: own\n",
        "  - A153: for free\n",
        "\n",
        "**Attribute 16:** (numerical)\n",
        "  - Number of existing credits at this bank\n",
        "\n",
        "**Attribute 17:** (qualitative)\n",
        "  *Job*\n",
        "  - A171: unemployed/ unskilled  - non-resident\n",
        "  - A172: unskilled - resident\n",
        "  - A173: skilled employee / official\n",
        "  - A174: management/ self-employed/ highly qualified employee/ officer\n",
        "\n",
        "**Attribute 18:** (numerical)\n",
        "  - Number of people being liable to provide maintenance for\n",
        "\n",
        "**Attribute 19:** (qualitative)\n",
        "  *Telephone*\n",
        "  - A191: none\n",
        "  - A192: yes, registered under the customer's name\n",
        "\n",
        "**Attribute 20:** (qualitative)\n",
        "  *Foreign worker*\n",
        "  - A201: yes\n",
        "  - A202: no\n"
      ],
      "metadata": {
        "id": "-eOyG7oVSqjE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinamento do Modelo\n",
        "\n",
        "Nesta etapa é executado um treinamento do modelo em cima do dataset fornecido que busca exportar um modelo treinado que será usado nas próximas etapas para identificação do comprador como um 'mau ou bom comprador'."
      ],
      "metadata": {
        "id": "3Zy6jUEw-YLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalação do scikit-learn (caso não esteja instalado)\n",
        "!pip install scikit-learn\n",
        "!pip install ucimlrepo\n",
        "\n",
        "# Importando bibliotecas necessárias\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "statlog_german_credit_data = fetch_ucirepo(id=144)\n",
        "\n",
        "# Supondo que 'class' seja a coluna-alvo\n",
        "X = statlog_german_credit_data.data.features\n",
        "y = statlog_german_credit_data.data.targets['class']\n",
        "\n",
        "# Identificando colunas categóricas\n",
        "categorical_cols = [col for col in X.columns if X[col].dtype == 'object']\n",
        "\n",
        "# Criando um ColumnTransformer para codificação one-hot\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(), categorical_cols)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Dividindo os dados em conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Pré-processando os dados\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "\n",
        "# Inicializando o RandomForestClassifier\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Treinando o modelo\n",
        "model.fit(X_train_preprocessed, y_train)\n",
        "\n",
        "# Realizando previsões no conjunto de teste\n",
        "y_pred = model.predict(X_test_preprocessed)\n",
        "\n",
        "# Avaliando o modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Exibindo os resultados\n",
        "print(f\"Acurácia: {accuracy}\")\n",
        "print(\"\\nMatriz de Confusão:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "id": "ZyTqLk2XTYJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resultados da Avaliação do Modelo\n",
        "\n",
        "### 1. Accuracy:\n",
        "Accuracy: 0.8\n",
        "- **Interpretação:** O modelo tem uma acurácia global de 80%.\n",
        "\n",
        "### 2. Matriz de Confusão:\n",
        "\n",
        "```\n",
        "[[131 10]\n",
        "[ 30 29]]\n",
        "```\n",
        "\n",
        "- **Interpretação:**\n",
        "  - **Verdadeiros Positivos (VP):** 131 instâncias corretamente previstas como '1'.\n",
        "  - **Verdadeiros Negativos (VN):** 29 instâncias corretamente previstas como '2'.\n",
        "  - **Falsos Positivos (FP):** 10 instâncias incorretamente previstas como '1'.\n",
        "  - **Falsos Negativos (FN):** 30 instâncias incorretamente previstas como '2'.\n",
        "\n",
        "### 3. Relatório de Classificação:\n",
        "\n",
        "    index  precisão    recall  f1-score   suporte\n",
        "       1       0.81      0.93      0.87       141\n",
        "       2       0.74      0.49      0.59        59\n",
        "\n",
        "accuracy                           0.80       200\n",
        "\n",
        "média ponderada 0.79 0.80 0.79 200\n",
        "\n",
        "- **Interpretação:**\n",
        "  - **Precisão para '1' (Bom):** 81%, **Recall:** 93%, **F1-Score:** 87%, **Suporte:** 141.\n",
        "  - **Precisão para '2' (Ruim):** 74%, **Recall:** 49%, **F1-Score:** 59%, **Suporte:** 59.\n",
        "\n",
        "### Resumo:\n",
        "- O modelo se sai bem na identificação de instâncias 'Bom' (classe '1') com alta precisão e recall.\n",
        "- No entanto, ele tem mais dificuldade com as instâncias 'Ruim' (classe '2'), onde o recall é menor.\n"
      ],
      "metadata": {
        "id": "2mFI18VNUPkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalação do scikit-learn (caso não esteja instalado)\n",
        "!pip install scikit-learn\n",
        "!pip install ucimlrepo\n",
        "\n",
        "# Importando bibliotecas necessárias\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import joblib\n",
        "\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "statlog_german_credit_data = fetch_ucirepo(id=144)\n",
        "\n",
        "# Supondo que 'class' seja a coluna-alvo\n",
        "X = statlog_german_credit_data.data.features\n",
        "y = statlog_german_credit_data.data.targets['class']\n",
        "\n",
        "# Identificando colunas categóricas\n",
        "categorical_cols = [col for col in X.columns if X[col].dtype == 'object']\n",
        "\n",
        "\n",
        "# Criando um ColumnTransformer para codificação one-hot\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(), categorical_cols)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Dividindo os dados em conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Pré-processando os dados\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "\n",
        "# Inicializando o RandomForestClassifier\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Definindo um grid de parâmetros para ajuste de hiperparâmetros\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Usando GridSearchCV para ajuste de hiperparâmetros\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
        "grid_search.fit(X_train_preprocessed, y_train)\n",
        "\n",
        "# Obtendo o melhor modelo do GridSearchCV\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Realizando previsões no conjunto de teste\n",
        "y_pred = best_model.predict(X_test_preprocessed)\n",
        "\n",
        "# Avaliando o modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Exibindo os resultados\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"\\nMatriz de Confusão:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_rep)\n",
        "\n",
        "# Exportando o melhor modelo\n",
        "joblib.dump(best_model, 'best_credit_risk_classifier_trained_model.pkl')\n"
      ],
      "metadata": {
        "id": "t1MQPiQeWimQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertendo os valores do exemplo em um DataFrame\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "# Carrega o modelo de predição\n",
        "loaded_model = joblib.load('best_credit_risk_classifier_trained_model.pkl')\n",
        "\n",
        "# Exemplos de input para predição\n",
        "sample_input = {\n",
        "    'Attribute1': 'A11',  # Status da conta corrente existente (Categórico)\n",
        "    'Attribute2': 12,     # Duração em Meses\n",
        "    'Attribute3': 'A30',  # Histórico de crédito (Categórico)\n",
        "    'Attribute4': 'A40',  # Propósito do crédito (Categórico)\n",
        "    'Attribute5': 5000,   # Quantidade de crédito\n",
        "    'Attribute6': 'A61',  # Poupança/obrigações de títulos (Categórico)\n",
        "    'Attribute7': 'A72',  # Emprego atual desde (Categórico)\n",
        "    'Attribute8': 3,      # Taxa de parcelamento em porcentagem da renda disponível\n",
        "    'Attribute9': 'A92',  # Estado civil e sexo (Categórico)\n",
        "    'Attribute10': 'A101',# Outros devedores/fiadores (Categórico)\n",
        "    'Attribute11': 4,     # Residência atual desde\n",
        "    'Attribute12': 'A121',# Tipo de propriedade (Categórico)\n",
        "    'Attribute13': 35,    # Idade em anos\n",
        "    'Attribute14': 'A141',# Outros planos de parcelamento (Categórico)\n",
        "    'Attribute15': 'A151',# Tipo de moradia (Categórico)\n",
        "    'Attribute16': 12,     # Número de créditos existentes neste banco\n",
        "    'Attribute17': 'A173',# Profissão (Categórico)\n",
        "    'Attribute18': 1,     # Número de pessoas obrigadas a fornecer sustento\n",
        "    'Attribute19': 'A192',# Telefone registrado sob o nome do cliente (Categórico)\n",
        "    'Attribute20': 'A201' # Trabalhador estrangeiro (Categórico)\n",
        "}\n",
        "\n",
        "# Converte o valor do input em um data frame\n",
        "sample_df = pd.DataFrame([sample_input])\n",
        "\n",
        "# Pré-processe a entrada da amostra usando o mesmo pré-processador usado durante o treinamento\n",
        "sample_preprocessed = preprocessor.transform(sample_df)\n",
        "\n",
        "# Faz predições com base no modelo importado\n",
        "prediction = loaded_model.predict(sample_preprocessed)\n",
        "\n",
        "# Exibe as predições\n",
        "print(f'The predicted class for the sample input is: {prediction[0]}')\n",
        "\n",
        "if prediction[0] == 2 :\n",
        "  print(f'The predicted class for the sample input is Bad')\n",
        "\n",
        "if prediction[0] == 1 :\n",
        "  print(f'The predicted class for the sample input is Good')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNIUA8hTZdss",
        "outputId": "6ba11a37-cb38-4845-9fda-46cb49190193"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted class for the sample input is: 2\n",
            "The predicted class for the sample input is Bad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpretação do Resultado do Modelo de Classificação de Risco de Crédito\n",
        "\n",
        "Quando analisamos a saída do modelo de classificação de risco de crédito, observamos que a classe prevista para o exemplo de entrada fornecido foi atribuída como \"2\". Neste contexto específico:\n",
        "\n",
        "- Classe 1: Pode ser associada a um nível de risco \"Bom\".\n",
        "- Classe 2: Pode ser associada a um nível de risco \"Ruim\".\n",
        "\n",
        "Portanto, a saída prediction[0] = 2 indica que o modelo classificou o exemplo de entrada como pertencente à classe de maior risco, ou seja, a classe \"Ruim\". Isso implica que, com base nas características específicas desse exemplo, o modelo identificou um potencial maior de risco de crédito.\n",
        "\n",
        "Em resumo, ao aplicar o modelo a um cenário específico, a classe predita (prediction[0]) representa a avaliação do modelo sobre o risco associado ao exemplo em questão. Neste caso, a classe \"Ruim\" sugere que o modelo considera esse exemplo como apresentando um nível mais elevado de risco de crédito."
      ],
      "metadata": {
        "id": "BxUnTubuZ04N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertendo os valores do exemplo em um DataFrame\n",
        "import pandas as pd\n",
        "# Supondo que 'best_model' seja o modelo treinado que você carregou\n",
        "import joblib\n",
        "\n",
        "# Carregando o modelo treinado\n",
        "best_model = joblib.load('best_credit_risk_classifier_trained_model.pkl')\n",
        "\n",
        "# Exemplo de entrada para um resultado 'bom'\n",
        "sample_input_bom = {\n",
        "    'Attribute1': 'A13',  # Alterado para uma faixa de checking account diferente\n",
        "    'Attribute2': 12,     # Duração em Meses\n",
        "    'Attribute3': 'A30',\n",
        "    'Attribute4': 'A40',\n",
        "    'Attribute5': 2000,   # Quantidade de crédito\n",
        "    'Attribute6': 'A61',\n",
        "    'Attribute7': 'A72',\n",
        "    'Attribute8': 3,\n",
        "    'Attribute9': 'A92',\n",
        "    'Attribute10': 'A101',\n",
        "    'Attribute11': 4,\n",
        "    'Attribute12': 'A121',\n",
        "    'Attribute13': 35,\n",
        "    'Attribute14': 'A141',\n",
        "    'Attribute15': 'A153',\n",
        "    'Attribute16': 12,\n",
        "    'Attribute17': 'A173',\n",
        "    'Attribute18': 1,\n",
        "    'Attribute19': 'A192',\n",
        "    'Attribute20': 'A202'\n",
        "}\n",
        "\n",
        "sample_input_df = pd.DataFrame([sample_input_bom])\n",
        "\n",
        "# Pré-processando os dados usando o mesmo transformer usado no treinamento\n",
        "sample_input_preprocessed = preprocessor.transform(sample_input_df)\n",
        "\n",
        "# Fazendo a predição\n",
        "prediction = best_model.predict(sample_input_preprocessed)\n",
        "\n",
        "# Resultado\n",
        "print(f'O modelo previu a classe para o exemplo de entrada como: {prediction}')\n",
        "\n",
        "\n",
        "if prediction[0] == 2 :\n",
        "  print(f'The predicted class for the sample input is Bad')\n",
        "\n",
        "if prediction[0] == 1 :\n",
        "  print(f'The predicted class for the sample input is Good')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNVylQ4fbYyn",
        "outputId": "ad1eacdd-ba97-420e-81c9-650aa9ce49ad"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O modelo previu a classe para o exemplo de entrada como: [1]\n",
            "The predicted class for the sample input is Good\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análise de resultados do modelo\n",
        "\n",
        "O modelo de machine learning construído para classificação de risco de crédito apresentou um desempenho satisfatório, com uma acurácia de 78,3% no conjunto de teste. No entanto, alguns pontos de atenção podem ser levantados:\n",
        "\n",
        "- O modelo tem uma tendência a classificar os clientes como bons pagadores, mesmo quando eles apresentam um risco maior de inadimplência. Isso pode ser devido ao fato de que o dataset utilizado para treinamento do modelo é relativamente equilibrado, com uma proporção de bons pagadores e maus pagadores de aproximadamente 50/50.\n",
        "- O modelo não é muito preciso na classificação de maus pagadores. A precisão do modelo para a classe \"mau pagador\" é de apenas 66,7%, o que significa que o modelo tem uma chance de 33,3% de classificar um mau pagador como bom pagador.\n",
        "\n",
        "Para melhorar o desempenho do modelo, é possível experimentar com diferentes algoritmos de machine learning e técnicas de pré-processamento de dados. Também é possível utilizar técnicas de ajuste de parâmetros para melhorar a precisão do modelo para a classe \"mau pagador\".\n",
        "\n",
        "## Conclusão\n",
        "\n",
        "O modelo de machine learning desenvolvido é uma ferramenta útil para avaliação do risco de crédito. No entanto, é importante estar ciente dos pontos de atenção mencionados anteriormente para evitar erros de classificação.\n",
        "\n",
        "A seguir, são apresentados alguns pontos adicionais que podem ser abordados na conclusão do problema como um todo:\n",
        "\n",
        "- Implicações do modelo para instituições financeiras: O modelo pode ser utilizado por instituições financeiras para tomar decisões mais informadas sobre empréstimos e outros serviços financeiros.\n",
        "- Limitações do modelo: O modelo é baseado em um dataset específico e pode não ser aplicável a outros contextos.\n",
        "- Próximos passos: O modelo pode ser aprimorado experimentando com diferentes algoritmos, técnicas de pré-processamento de dados e técnicas de ajuste de parâmetros."
      ],
      "metadata": {
        "id": "2WfUCWwo4_hu"
      }
    }
  ]
}